{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary packages\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import LabelBinarizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup constants\n",
    "DATASET_DIRECTORY = 'C:/Users/thoma/Documents/CSU East Bay/2nd Year/Fall 2019/CS 663/Projects/Project 3/Video Dataset (Full)'\n",
    "TENSORBOARD_LOG_DIRECTORY = \"logs\"\n",
    "NUM_EPOCHS = 20\n",
    "SEQUENCE_LENGTH = 40\n",
    "FEATURE_LENGTH = 1280\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = ['MoveLeft','MoveRight','MoveStraight']\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a keras Sequential model with 1) Masking layer  2) LSTM layer with 512 cells, dropout 0.5, recurrent_dropout of 0.5  \n",
    "# 3) a fully connected relu activation layer with 256 outputs,  4) a droupout layer 5) a final decision fully connected layer of length of labels\n",
    "# (which is the number of classes) with softmax activation\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Masking(mask_value=0.),\n",
    "    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(LABELS), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy', 'top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the filenames and paths for the training and validation datasets\n",
    "training_file = os.path.join(DATASET_DIRECTORY,'TrainList.txt')\n",
    "validation_file = os.path.join(DATASET_DIRECTORY,'ValidateList.txt')\n",
    "\n",
    "with open(training_file) as f:\n",
    "    training_list = [row.strip() for row in list(f)]\n",
    "\n",
    "with open(validation_file) as f:\n",
    "    validation_list = [row.strip() for row in list(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a generator that will yield a numpy array of video\n",
    "# features and the encoded class label\n",
    "def make_generator(file_list):\n",
    "    def generator():\n",
    "        np.random.shuffle(file_list)\n",
    "        for path in file_list:\n",
    "            class_label = os.path.basename(os.path.dirname(path))\n",
    "            features = np.load(path)\n",
    "\n",
    "            padded_sequence = np.zeros((SEQUENCE_LENGTH, FEATURE_LENGTH))\n",
    "            padded_sequence[0:len(features)] = np.array(features)\n",
    "\n",
    "            transformed_label = encoder.transform([class_label])\n",
    "            yield padded_sequence, transformed_label[0]\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the training and validation datasets   \n",
    "train_dataset = tf.data.Dataset.from_generator(make_generator(training_list),\n",
    "                 output_types=(tf.float32, tf.int16),\n",
    "                 output_shapes=((SEQUENCE_LENGTH, FEATURE_LENGTH), (len(LABELS))))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE,drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(make_generator(validation_list),\n",
    "                 output_types=(tf.float32, tf.int16),\n",
    "                 output_shapes=((SEQUENCE_LENGTH, FEATURE_LENGTH), (len(LABELS))))\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE,drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directory for the Tensorboard logging files\n",
    "if not os.path.exists(TENSORBOARD_LOG_DIRECTORY):\n",
    "    os.mkdir(TENSORBOARD_LOG_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 30s 558ms/step - loss: 1.2595 - accuracy: 0.4259 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 30s 551ms/step - loss: 0.9517 - accuracy: 0.5630 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7810 - val_accuracy: 0.6333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 30s 550ms/step - loss: 0.7801 - accuracy: 0.5889 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7313 - val_accuracy: 0.6778 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 30s 551ms/step - loss: 0.7269 - accuracy: 0.6778 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 0.7222 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 30s 552ms/step - loss: 0.7076 - accuracy: 0.7111 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.6556 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 30s 552ms/step - loss: 0.7197 - accuracy: 0.7074 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7945 - val_accuracy: 0.6333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 42s 769ms/step - loss: 0.6384 - accuracy: 0.7111 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.6889 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 37s 680ms/step - loss: 0.5963 - accuracy: 0.7333 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6612 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 37s 692ms/step - loss: 0.5066 - accuracy: 0.7926 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6996 - val_accuracy: 0.7222 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.5219 - accuracy: 0.7852 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 35s 649ms/step - loss: 0.4786 - accuracy: 0.8037 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8232 - val_accuracy: 0.6556 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 44s 820ms/step - loss: 0.4326 - accuracy: 0.8444 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7394 - val_accuracy: 0.7667 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 45s 834ms/step - loss: 0.4119 - accuracy: 0.8370 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.6667 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 35s 644ms/step - loss: 0.4071 - accuracy: 0.8407 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.6889 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.3666 - accuracy: 0.8556 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7509 - val_accuracy: 0.7111 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 35s 657ms/step - loss: 0.2702 - accuracy: 0.8963 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8324 - val_accuracy: 0.7333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 32s 588ms/step - loss: 0.2648 - accuracy: 0.8852 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9337 - val_accuracy: 0.7333 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 32s 585ms/step - loss: 0.3454 - accuracy: 0.8852 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8466 - val_accuracy: 0.7556 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 34s 622ms/step - loss: 0.3690 - accuracy: 0.8926 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8757 - val_accuracy: 0.7778 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 31s 572ms/step - loss: 0.2747 - accuracy: 0.9000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1468 - val_accuracy: 0.7222 - val_top_k_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205782999b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model using the datasets and use TensorBoard to view the model's training results\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = TENSORBOARD_LOG_DIRECTORY, update_freq='epoch')\n",
    "model.fit(train_dataset, epochs=NUM_EPOCHS, callbacks=[tensorboard_callback], validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 14344."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the TensorBoard notebook extension.\n",
    "# if TensorBoard does not begin in the notebook then open a new broswer tab \n",
    "# and in the search bar type 'http://localhost:8086' to view the TensorBoard results\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"logs\" --host localhost --port=8086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model as a HDF5 file with the current date and time in the filename\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_file = \"LSTM_MODEL_V1_\" + timestr + \".h5\"\n",
    "model.save(model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
